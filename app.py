import streamlit as st
import os
from utils.extract_text import extract_text_from_pdf
from utils.keyword_extractor import extract_keywords
from utils.blooms_classifier import classify_blooms_level

# Setup folder
SAMPLE_SYLLABI_DIR = "sample_syllabi"
os.makedirs(SAMPLE_SYLLABI_DIR, exist_ok=True)

# Page Config
st.set_page_config(page_title="ğŸ“˜ Syllabus & Curriculum Optimizer", layout="wide")

# Sidebar Navigation
st.sidebar.title("ğŸ” Navigation")
page = st.sidebar.radio("Choose Section", ["ğŸ  Home", "ğŸ“¤ Upload & Extract", "ğŸ”‘ Keyword Analysis", "ğŸ¯ Bloom's Classification"])

st.title("ğŸ“˜ Syllabus & Curriculum Design Optimizer")

# Session state
if 'syllabus_text' not in st.session_state:
    st.session_state.syllabus_text = ""
if 'file_uploaded' not in st.session_state:
    st.session_state.file_uploaded = False

# ğŸ  Home
if page == "ğŸ  Home":
    st.markdown("""
        Welcome to the **Syllabus & Curriculum Design Optimizer** ğŸ“  
        This tool helps faculty and educators to:
        - ğŸ“¤ Upload Syllabus PDFs  
        - ğŸ“„ Extract structured text  
        - ğŸ”‘ Identify key concepts  
        - ğŸ¯ Classify learning objectives using **Bloom's Taxonomy**

        ğŸ‘‰ Start by selecting **Upload & Extract** from the sidebar.
    """)

# ğŸ“¤ Upload & Extract
elif page == "ğŸ“¤ Upload & Extract":
    st.subheader("ğŸ“¤ Upload Your Syllabus PDF")
    uploaded_file = st.file_uploader("Choose a PDF file", type=["pdf"])

    if uploaded_file:
        file_path = os.path.join(SAMPLE_SYLLABI_DIR, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        with st.spinner("ğŸ” Extracting text from PDF..."):
            try:
                syllabus_text = extract_text_from_pdf(file_path)
                st.session_state.syllabus_text = syllabus_text
                st.session_state.file_uploaded = True
                st.success("âœ… Text successfully extracted!")

                st.subheader("ğŸ“„ Extracted Text Preview")
                st.text_area("Preview", syllabus_text[:3000] + "..." if len(syllabus_text) > 3000 else syllabus_text, height=300)
            except Exception as e:
                st.error(f"âŒ Error extracting text: {e}")

# ğŸ”‘ Keyword Analysis
elif page == "ğŸ”‘ Keyword Analysis":
    st.subheader("ğŸ”‘ Extract Keywords")
    if st.session_state.file_uploaded:
        with st.spinner("ğŸ” Extracting keywords..."):
            keywords = extract_keywords(st.session_state.syllabus_text)
        st.success("âœ… Keywords extracted!")
        st.write(", ".join(keywords))
    else:
        st.warning("âš ï¸ Please upload a syllabus first in 'Upload & Extract' tab.")

# ğŸ¯ Bloom's Classification
elif page == "ğŸ¯ Bloom's Classification":
    st.subheader("ğŸ¯ Classify Learning Objectives by Bloomâ€™s Levels")
    if st.session_state.file_uploaded:
        with st.spinner("ğŸ” Analyzing text..."):
            try:
                # Simple sentence splitter (alternative to nltk.sent_tokenize)
                sentences = st.session_state.syllabus_text.split('.')
                sentences = [s.strip() for s in sentences if s.strip()]
                bloom_results = classify_blooms_level(sentences)
            except Exception as e:
                st.error(f"âŒ Failed to classify Bloom's levels: {e}")
                bloom_results = []

        if bloom_results:
            st.write("Bloom Results Preview:", bloom_results)
            for sentence, level in bloom_results:
                st.markdown(f"- **{sentence.strip()}** â†’ ğŸ§  *{level}*")
        else:
            st.info("â„¹ï¸ No learning objectives were found.")
    else:
        st.warning("âš ï¸ Please upload a syllabus first in 'Upload & Extract' tab.")
